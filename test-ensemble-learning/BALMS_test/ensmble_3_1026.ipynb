{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yg4XRjpysJk6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Optional\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "def compute_uce(probs, targets, n_bins=100):\n",
    "    _, nattrs =probs.size()\n",
    "    nattrs = torch.tensor(nattrs)\n",
    "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    uce = 0\n",
    "    bin_uncertainties = []\n",
    "    bin_errors = []\n",
    "    prop_in_bin_values = []\n",
    "    bin_n_samples = []\n",
    "    bin_variances = []\n",
    "    # Compute the uncertainty values (entropy)\n",
    "    uncertainties = (1/torch.log(nattrs))*(-torch.sum(probs * torch.log(probs + 1e-12), dim=1))\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        in_bin = (uncertainties >= bin_lower) * (uncertainties < bin_upper)\n",
    "        prop_in_bin = in_bin.float().mean()\n",
    "        prop_in_bin_values.append(prop_in_bin.item() if prop_in_bin.item() > 0 else None)\n",
    "        if prop_in_bin.item() > 0:\n",
    "            sample_indices = torch.where(in_bin)[0]\n",
    "            bin_targets = targets[sample_indices]\n",
    "            bin_probs = probs[sample_indices]\n",
    "            error_in_bin = (bin_targets != torch.argmax(bin_probs, dim=1)).float().mean()\n",
    "            avg_uncertainty_in_bin = uncertainties[in_bin].mean()\n",
    "            uce += torch.abs(avg_uncertainty_in_bin - error_in_bin) * prop_in_bin\n",
    "            bin_uncertainties.append(avg_uncertainty_in_bin.item())\n",
    "            bin_errors.append(error_in_bin.item())\n",
    "            n_samples_in_bin = sample_indices.size(0)\n",
    "            bin_n_samples.append(n_samples_in_bin)\n",
    "            bin_variances.append(torch.var((bin_targets != torch.argmax(bin_probs, dim=1)).float()).item())\n",
    "        else:\n",
    "            bin_uncertainties.append(None)\n",
    "            bin_errors.append(None)\n",
    "            bin_n_samples.append(None)\n",
    "            bin_variances.append(None)\n",
    "\n",
    "    return uce, bin_uncertainties, bin_errors, prop_in_bin_values, bin_n_samples, bin_variances\n",
    "\n",
    "\n",
    "def find_error_rates(uncertainties, bin_uncertainties, bin_errors):\n",
    "    error_rates = []\n",
    "    for uncertainty in uncertainties:\n",
    "        found = False\n",
    "        for idx, (bin_uncertainty_lower, bin_uncertainty_upper, bin_error) in enumerate(zip(bin_uncertainties[:-1], bin_uncertainties[1:], bin_errors)):\n",
    "            if bin_uncertainty_lower is not None and bin_uncertainty_upper is not None and bin_error is not None:\n",
    "                if bin_uncertainty_lower <= uncertainty.item() < bin_uncertainty_upper:\n",
    "\n",
    "                    error_rates.append(bin_error)\n",
    "                    found = True\n",
    "                    break\n",
    "        if not found:\n",
    "            found_= False\n",
    "            if bin_uncertainties[0] is not None:\n",
    "                if 0 <=uncertainty< bin_uncertainties[0]:\n",
    "                    error_rates.append(bin_errors[0])\n",
    "                    found_= True\n",
    "                else:\n",
    "                    for bin_error in reversed(bin_errors):\n",
    "                        if bin_error is not None:\n",
    "                            error_rates.append(bin_error)\n",
    "                            found_= True\n",
    "                            break\n",
    "            else:\n",
    "                if bin_uncertainties[1] is not None:\n",
    "                    error_rates.append(bin_errors[1])\n",
    "                    found_= True\n",
    "                else:\n",
    "                    error_rates.append(bin_errors[2])\n",
    "                    found_= True\n",
    "\n",
    "            if not found_:\n",
    "                if bin_uncertainties[4] is not None and 0 <=uncertainty< bin_uncertainties[4]:\n",
    "                    error_rates.append(bin_errors[4])\n",
    "                    found_= True\n",
    "            if not found_:\n",
    "                if bin_uncertainties[8] is not None and bin_uncertainties[8] <=uncertainty< 1:\n",
    "                    error_rates.append(bin_errors[8])\n",
    "                    found_= True\n",
    "\n",
    "\n",
    "    return torch.tensor(error_rates)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "\n",
    "    # 計算正確預測的數量\n",
    "    correct_predictions = torch.sum(y_true == y_pred)\n",
    "\n",
    "    # 計算準確度\n",
    "    accuracy = correct_predictions.item() / y_true.size(0)\n",
    "\n",
    "    return accuracy\n",
    "def choose_best_expert_ex(probs_expert1, probs_expert2, targets,val_uce_list_ep1,val_uce_list_ep2, n_bins=10):\n",
    "    # Compute UCE and bin values for both experts\n",
    "\n",
    "#     uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1, bin_variances_ep1 = compute_uce(probs_expert1, targets, n_bins)\n",
    "#     uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2, bin_variances_ep2 = compute_uce(probs_expert2, targets, n_bins)\n",
    "\n",
    "    uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1,bin_variances_ep1 = val_uce_list_ep1[0],val_uce_list_ep1[1],val_uce_list_ep1[2],val_uce_list_ep1[3],val_uce_list_ep1[4],val_uce_list_ep1[5]\n",
    "    uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2,bin_variances_ep2 = val_uce_list_ep2[0],val_uce_list_ep2[1],val_uce_list_ep2[2],val_uce_list_ep2[3],val_uce_list_ep2[4],val_uce_list_ep2[5]\n",
    "\n",
    "    # Compute uncertainties for both experts\n",
    "    _, nattrs = probs_expert1.size()\n",
    "    nattrs = torch.tensor(nattrs)\n",
    "    uncertainties_expert1 = (1/torch.log(nattrs))*(-torch.sum(probs_expert1 * torch.log(probs_expert1 + 1e-12), dim=1))\n",
    "    uncertainties_expert2 = (1/torch.log(nattrs))*(-torch.sum(probs_expert2 * torch.log(probs_expert2 + 1e-12), dim=1))\n",
    "    # Find error rates for both experts\n",
    "    error_rates_expert1 = find_error_rates(uncertainties_expert1, bin_uncertainties_expert1, bin_errors_expert1)\n",
    "    error_rates_expert2 = find_error_rates(uncertainties_expert2, bin_uncertainties_expert2, bin_errors_expert2)\n",
    "    # Choose the expert with lower error rate for each sample\n",
    "    chosen_expert = (error_rates_expert1 < error_rates_expert2)\n",
    "\n",
    "    # Get the predictions from both experts\n",
    "    preds_expert1 = torch.argmax(probs_expert1, dim=1)\n",
    "    preds_expert2 = torch.argmax(probs_expert2, dim=1)\n",
    "\n",
    "    # Choose the final prediction based on the chosen expert\n",
    "    final_predictions = torch.where(chosen_expert, preds_expert1, preds_expert2)\n",
    "\n",
    "    return final_predictions\n",
    "\n",
    "\n",
    "def choose_best_three_expert(probs_expert1,probs_expert2,probs_expert3 ,targets,val_uce_list_ep1,val_uce_list_ep2,val_uce_list_ep3, n_bins=10):\n",
    "\n",
    "\n",
    "#     uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1, bin_variances_ep1 = compute_uce(probs_expert1, targets, n_bins)\n",
    "#     uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2, bin_variances_ep2 = compute_uce(probs_expert2, targets_pairs, n_bins)\n",
    "#     uce_expert3, bin_uncertainties_expert3, bin_errors_expert3, prop_in_bin_values_expert3,bin_n_samples_ep3, bin_variances_ep3 = compute_uce(probs_expert3, targets, n_bins)\n",
    "    uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1,bin_variances_ep1 = val_uce_list_ep1[0],val_uce_list_ep1[1],val_uce_list_ep1[2],val_uce_list_ep1[3],val_uce_list_ep1[4],val_uce_list_ep1[5]\n",
    "    uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2,bin_variances_ep2 = val_uce_list_ep2[0],val_uce_list_ep2[1],val_uce_list_ep2[2],val_uce_list_ep2[3],val_uce_list_ep2[4],val_uce_list_ep2[5]\n",
    "    uce_expert3, bin_uncertainties_expert3, bin_errors_expert3, prop_in_bin_values_expert3,bin_n_samples_ep3,bin_variances_ep3 = val_uce_list_ep3[0],val_uce_list_ep3[1],val_uce_list_ep3[2],val_uce_list_ep3[3],val_uce_list_ep3[4],val_uce_list_ep3[5]\n",
    "\n",
    "\n",
    "\n",
    "    # Compute uncertainties for both experts\n",
    "    _, nattrs = probs_expert1.size()\n",
    "    nattrs = torch.tensor(nattrs)\n",
    "    uncertainties_expert1 = (1/torch.log(nattrs))*(-torch.sum(probs_expert1 * torch.log(probs_expert1 + 1e-12), dim=1))\n",
    "    uncertainties_expert2 = (1/torch.log(nattrs))*(-torch.sum(probs_expert2 * torch.log(probs_expert2 + 1e-12), dim=1))\n",
    "    uncertainties_expert3 = (1/torch.log(nattrs))*(-torch.sum(probs_expert3 * torch.log(probs_expert3 + 1e-12), dim=1))\n",
    "\n",
    "    # Find error rates for both experts\n",
    "    error_rates_expert1 = find_error_rates(uncertainties_expert1, bin_uncertainties_expert1, bin_errors_expert1)\n",
    "    error_rates_expert2 = find_error_rates(uncertainties_expert2, bin_uncertainties_expert2, bin_errors_expert2)\n",
    "    error_rates_expert3 = find_error_rates(uncertainties_expert3, bin_uncertainties_expert3, bin_errors_expert3)\n",
    "    # Choose the expert with lower error rate for each sample\n",
    "\n",
    "    # Get the predictions from both experts\n",
    "    preds_expert1 = torch.argmax(probs_expert1, dim=1)\n",
    "    preds_expert2 = torch.argmax(probs_expert2, dim=1)\n",
    "    preds_expert3 = torch.argmax(probs_expert3, dim=1)\n",
    "\n",
    "    # 將三個錯誤率堆疊成一個張量\n",
    "    error_rates = torch.stack([error_rates_expert1, error_rates_expert2, error_rates_expert3])\n",
    "\n",
    "    # 找出最小錯誤率的索引\n",
    "    _, min_error_rate_indices = torch.min(error_rates, dim=0)\n",
    "\n",
    "    # 根據最小錯誤率的索引選擇最終的預測\n",
    "    final_predictions = torch.where(min_error_rate_indices == 0, preds_expert1,\n",
    "                                    torch.where(min_error_rate_indices == 1, preds_expert2, preds_expert3))\n",
    "    \n",
    "    \n",
    "    POE_probs_ = torch.stack([probs_expert1, probs_expert2,probs_expert3])\n",
    "    POE_probs = product_of_experts(POE_probs_)\n",
    "    POE_pred = np.argmax(POE_probs, axis=1)\n",
    "    \n",
    "    POE_pred = torch.tensor(POE_pred)  # Convert numpy array to torch tensor\n",
    "\n",
    "    SOE_probs_ = (probs_expert1+probs_expert2+probs_expert3)/3\n",
    "    SOE_pred = np.argmax(SOE_probs_, axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    initial_predictions_probs = torch.where(min_error_rate_indices.unsqueeze(-1) == 0, probs_expert1,\n",
    "                                           torch.where(min_error_rate_indices.unsqueeze(-1) == 1, probs_expert2, probs_expert3))\n",
    "    \n",
    "    uce_expert_SPE, _, _, _,_,_ =compute_uce(initial_predictions_probs, targets)\n",
    "    uce_expert_SOE, _, _, _,_,_ =compute_uce(SOE_probs_, targets)\n",
    "    uce_expert_POE, _, _, _,_,_ =compute_uce(POE_probs, targets)\n",
    "    print(\"SPE_UCE: \",uce_expert_SPE,\"SOE_UCE: \",uce_expert_SOE,\"POE_UCE: \",uce_expert_POE)\n",
    "    return final_predictions\n",
    "\n",
    "def voting(preds_expert1: List[int], preds_expert2: List[int], preds_expert3: List[int], default_expert: int) -> torch.Tensor:\n",
    "    assert default_expert in [1, 2, 3], \"Default expert must be either 1, 2, or 3\"\n",
    "\n",
    "    final_preds = []\n",
    "    for p1, p2, p3 in zip(preds_expert1, preds_expert2, preds_expert3):\n",
    "        vote_counts = Counter([p1, p2, p3])\n",
    "        max_vote_count = max(vote_counts.values())\n",
    "        most_common = [k for k, v in vote_counts.items() if v == max_vote_count]\n",
    "\n",
    "        if len(most_common) > 1:\n",
    "            if default_expert == 1:\n",
    "                final_preds.append(p1)\n",
    "            elif default_expert == 2:\n",
    "                final_preds.append(p2)\n",
    "            else:  # default_expert == 3\n",
    "                final_preds.append(p3)\n",
    "        else:\n",
    "            final_preds.append(most_common[0])\n",
    "\n",
    "    final_preds = torch.tensor(final_preds, dtype=torch.int64)  # or your desired data type\n",
    "    return final_preds\n",
    "def weighted_voting(preds_expert1: List[int], preds_expert2: List[int], preds_expert3: List[int], weights: List[float], default_expert: int) -> torch.Tensor:\n",
    "    assert default_expert in [1, 2, 3], \"Default expert must be either 1, 2, or 3\"\n",
    "\n",
    "    final_preds = []\n",
    "    for p1, p2, p3 in zip(preds_expert1, preds_expert2, preds_expert3):\n",
    "        weighted_vote_counts = Counter()\n",
    "        for pred, weight in zip([p1, p2, p3], weights):\n",
    "            weighted_vote_counts[pred] += weight\n",
    "\n",
    "        max_vote_count = max(weighted_vote_counts.values())\n",
    "        most_common = [k for k, v in weighted_vote_counts.items() if v == max_vote_count]\n",
    "\n",
    "        if len(most_common) > 1:\n",
    "            if default_expert == 1:\n",
    "                final_preds.append(p1)\n",
    "            elif default_expert == 2:\n",
    "                final_preds.append(p2)\n",
    "            else:  # default_expert == 3\n",
    "                final_preds.append(p3)\n",
    "        else:\n",
    "            final_preds.append(most_common[0])\n",
    "\n",
    "    final_preds = torch.tensor(final_preds, dtype=torch.int64)  # or your desired data type\n",
    "    return final_preds\n",
    "def product_of_experts(predictions):\n",
    "    # Multiply predictions together\n",
    "    product = torch.prod(predictions, dim=0)\n",
    "\n",
    "    # Normalize result\n",
    "    product /= torch.sum(product)\n",
    "\n",
    "    return product\n",
    "\n",
    "def weighted_voting_(prob_expert1: List[float], prob_expert2: List[float], weights: List[float], default_expert: int) -> torch.Tensor:\n",
    "    assert default_expert in [1, 2], \"Default expert must be either 1 or 2\"\n",
    "\n",
    "    final_probs = []\n",
    "    for p1, p2 in zip(prob_expert1, prob_expert2):\n",
    "        weighted_probs = Counter()\n",
    "        for prob, weight in zip([p1, p2], weights):\n",
    "            weighted_probs[prob] += weight\n",
    "\n",
    "        max_prob_count = max(weighted_probs.values())\n",
    "        most_common = [k for k, v in weighted_probs.items() if v == max_prob_count]\n",
    "\n",
    "        if len(most_common) > 1:\n",
    "            if default_expert == 1:\n",
    "                final_probs.append(p1)\n",
    "            else:  # default_expert == 2\n",
    "                final_probs.append(p2)\n",
    "        else:\n",
    "            final_probs.append(most_common[0])\n",
    "\n",
    "    final_probs = torch.tensor(final_probs, dtype=torch.float32)  # or your desired data type\n",
    "    return final_probs\n",
    "\n",
    "def voting_(prob_expert1: Optional[List[float]], prob_expert2: Optional[List[float]], default_expert: int) -> torch.Tensor:\n",
    "    assert default_expert in [1, 2], \"Default expert must be either 1 or 2\"\n",
    "\n",
    "    final_probs = []\n",
    "    for p1, p2 in zip(prob_expert1, prob_expert2):\n",
    "        prob_counts = Counter([p for p in [p1, p2] if p is not None])\n",
    "        if not prob_counts:  # All predictions are None\n",
    "            final_probs.append(None)\n",
    "            continue\n",
    "\n",
    "        max_prob_count = max(prob_counts.values())\n",
    "        most_common = [k for k, v in prob_counts.items() if v == max_prob_count]\n",
    "\n",
    "        if len(most_common) > 1:\n",
    "            if default_expert == 1:\n",
    "                final_probs.append(p1)\n",
    "            else:  # default_expert == 2\n",
    "                final_probs.append(p2)\n",
    "        else:\n",
    "            final_probs.append(most_common[0])\n",
    "\n",
    "    final_probs = torch.tensor(final_probs, dtype=torch.float32)  # or your desired data type\n",
    "    return final_probs\n",
    "\n",
    "# def plot_dot_UCE_diagram(uce_value, bin_uncertainties, bin_errors, prop_in_bin_values, bin_n_samples, bin_variances, model_index, threshold=0.005):\n",
    "#     global save_name\n",
    "#     plt.figure(figsize=(6, 6))\n",
    "#     plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Perfect calibration\")\n",
    "    \n",
    "#     # 筛选prop_in_bin值大于等于threshold的点\n",
    "#     valid_indices = [i for i, prop in enumerate(prop_in_bin_values) if prop is not None and prop >= threshold]\n",
    "#     valid_bin_uncertainties = [bin_uncertainties[i] for i in valid_indices]\n",
    "#     valid_bin_errors = [bin_errors[i] for i in valid_indices]\n",
    "#     valid_prop_in_bin_values = [prop_in_bin_values[i] for i in valid_indices]\n",
    "#     valid_bin_n_samples  = [bin_n_samples[i] for i in valid_indices]\n",
    "#     valid_bin_variances  = [bin_variances[i] for i in valid_indices]\n",
    "    \n",
    "#     plt.scatter(valid_bin_uncertainties, valid_bin_errors, marker='o', color='blue', label=\"Model {}\".format(model_index ))\n",
    "#     plt.xlabel(\"Uncertainty\", fontsize=14)\n",
    "#     plt.ylabel(\"Error\", fontsize=14)\n",
    "#     plt.title(\"Reliability Diagram for Model {} (UCE={:.4f})\".format(model_index , uce_value.item()), fontsize=16)\n",
    "#     plt.xlim(0, 1)\n",
    "#     plt.ylim(0, 1)\n",
    "#     plt.xticks(np.arange(0, 1.1, 0.1), fontsize=12)\n",
    "#     plt.yticks(np.arange(0, 1.1, 0.1), fontsize=12)\n",
    "#     plt.grid(color='gray', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "#     plt.gca().set_axisbelow(True)\n",
    "#     plt.legend(fontsize=12)\n",
    "#     plt.tight_layout()\n",
    "\n",
    "#     for i, txt in enumerate(valid_bin_n_samples):\n",
    "#         plt.annotate(\"n={}\".format(txt), (valid_bin_uncertainties[i], valid_bin_errors[i]), fontsize=8, ha='center', va='bottom', textcoords=\"offset points\", xytext=(0,5))\n",
    "#         plt.annotate(\"var={:.2f}\".format(valid_bin_variances[i]), (valid_bin_uncertainties[i], valid_bin_errors[i]), fontsize=8, ha='center', va='bottom', textcoords=\"offset points\", xytext=(0,20))\n",
    "#     Path('plt/').mkdir(parents=True, exist_ok=True)\n",
    "#     plt.savefig('plt/'+save_name +\"UCE_model_{}.svg\".format(model_index))\n",
    "#     plt.close()\n",
    "    \n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.cm as cm\n",
    "def plot_dot_UCE_diagram(uce_value, bin_uncertainties, bin_errors, prop_in_bin_values, bin_n_samples, bin_variances, model_index, threshold=0.005):\n",
    "    global save_name\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Perfect calibration\")\n",
    "    \n",
    "    # 筛选prop_in_bin值大于等于threshold的点\n",
    "    valid_indices = [i for i, prop in enumerate(prop_in_bin_values) if prop is not None and prop >= threshold]\n",
    "    valid_bin_uncertainties = [bin_uncertainties[i] for i in valid_indices]\n",
    "    valid_bin_errors = [bin_errors[i] for i in valid_indices]\n",
    "    valid_prop_in_bin_values = [prop_in_bin_values[i] for i in valid_indices]\n",
    "    valid_bin_n_samples  = [bin_n_samples[i] for i in valid_indices]\n",
    "    valid_bin_variances  = [bin_variances[i] for i in valid_indices]\n",
    "    \n",
    "    # 计算中心点\n",
    "    centers = [0.05 + 0.1 * i for i in range(10)]\n",
    "    bins = [0 + 0.1 * i for i in range(11)]  # Including the rightmost edge for binning\n",
    "    \n",
    "    # 对bin_uncertainties值进行分箱，并找到对应的中心点\n",
    "    hist_values = np.digitize(valid_bin_uncertainties, bins) - 1\n",
    "    hist_centers = [centers[i] for i in hist_values]\n",
    "    \n",
    "    # Use Normalize and colormap to change the color of the bars based on bin_n_samples\n",
    "    norm = Normalize(vmin=min(valid_bin_n_samples), vmax=max(valid_bin_n_samples))\n",
    "    colormap = cm.cividis   # Changed to plasma colormap\n",
    "    colors = [colormap(norm(value)) for value in valid_bin_n_samples]\n",
    "    \n",
    "    plt.bar(hist_centers, valid_bin_errors, width=0.05, color=colors)\n",
    "    plt.xlabel(\"Uncertainty\", fontsize=14)\n",
    "    plt.ylabel(\"Error\", fontsize=14)\n",
    "    plt.title(\"Reliability Diagram for Model {} (UCE={:.4f})\".format(model_index , uce_value.item()), fontsize=16)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xticks(np.arange(0, 1.1, 0.1), fontsize=12)\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1), fontsize=12)\n",
    "    plt.grid(color='gray', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "    plt.gca().set_axisbelow(True)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    sm = cm.ScalarMappable(cmap=colormap, norm=norm)\n",
    "    sm.set_array([])  # You can set a dummy array\n",
    "    cbar = plt.colorbar(sm, orientation='vertical', label='Number of Samples')\n",
    "    cbar.set_label('Number of Samples', rotation=270, labelpad=15)\n",
    "\n",
    "    for i, txt in enumerate(valid_bin_n_samples):\n",
    "        plt.annotate(\"n={}\".format(txt), (hist_centers[i], valid_bin_errors[i]), fontsize=8, ha='center', va='bottom', textcoords=\"offset points\", xytext=(0,5))\n",
    "#         plt.annotate(\"var={:.2f}\".format(valid_bin_variances[i]), (hist_centers[i], valid_bin_errors[i]), fontsize=8, ha='center', va='bottom', textcoords=\"offset points\", xytext=(0,20))\n",
    "\n",
    "    Path('plt/').mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig('plt/'+save_name +\"UCE_model_{}.svg\".format(model_index))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 原本的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "B7tsE0hLKlie"
   },
   "outputs": [],
   "source": [
    "def cal_val_state(ep1_logits,ep2_logits,ep3_logits,labels,phase):\n",
    "  global val_uce_list_ep1\n",
    "  global val_uce_list_ep2\n",
    "  global val_uce_list_ep3\n",
    "\n",
    "  ep1_logits = F.softmax(ep1_logits, dim=1)\n",
    "  ep2_logits = F.softmax(ep2_logits, dim=1)\n",
    "  ep3_logits = F.softmax(ep3_logits, dim=1)\n",
    "\n",
    "  if phase=='val':\n",
    "    uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1, bin_variances_ep1 = compute_uce(ep1_logits, labels)\n",
    "    val_uce_list_ep1.append(uce_expert1)\n",
    "    val_uce_list_ep1.append(bin_uncertainties_expert1)\n",
    "    val_uce_list_ep1.append(bin_errors_expert1)\n",
    "    val_uce_list_ep1.append(prop_in_bin_values_expert1)\n",
    "    val_uce_list_ep1.append(bin_n_samples_ep1)\n",
    "    val_uce_list_ep1.append(bin_variances_ep1)\n",
    "\n",
    "    uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2, bin_variances_ep2 = compute_uce(ep2_logits, labels)\n",
    "    val_uce_list_ep2.append(uce_expert2)\n",
    "    val_uce_list_ep2.append(bin_uncertainties_expert2)\n",
    "    val_uce_list_ep2.append(bin_errors_expert2)\n",
    "    val_uce_list_ep2.append(prop_in_bin_values_expert2)\n",
    "    val_uce_list_ep2.append(bin_n_samples_ep2)\n",
    "    val_uce_list_ep2.append(bin_variances_ep2)\n",
    "\n",
    "    uce_expert3, bin_uncertainties_expert3, bin_errors_expert3, prop_in_bin_values_expert3,bin_n_samples_ep3, bin_variances_ep3 = compute_uce(ep3_logits, labels)\n",
    "    val_uce_list_ep3.append(uce_expert3)\n",
    "    val_uce_list_ep3.append(bin_uncertainties_expert3)\n",
    "    val_uce_list_ep3.append(bin_errors_expert3)\n",
    "    val_uce_list_ep3.append(prop_in_bin_values_expert3)\n",
    "    val_uce_list_ep3.append(bin_n_samples_ep3)\n",
    "    val_uce_list_ep3.append(bin_variances_ep3)\n",
    "    \n",
    "#     tabel_pred_ep123 = choose_best_three_expert(ep1_logits,ep2_logits,ep3_logits,labels,val_uce_list_ep1,val_uce_list_ep2,val_uce_list_ep3)\n",
    "#     tabel_acc_ep123 = accuracy(tabel_pred_ep123,labels)\n",
    "    \n",
    "#     tabel_pred_ep123_new = choose_best_three_expert_new(ep1_logits,ep2_logits,ep3_logits,labels,val_uce_list_ep1,val_uce_list_ep2,val_uce_list_ep3)\n",
    "#     tabel_acc_ep123_new = accuracy(tabel_pred_ep123_new,labels)\n",
    "    \n",
    "#     print(\"123: \" ,tabel_acc_ep123 ,\"123_new: \",tabel_acc_ep123_new)\n",
    "  else:\n",
    "    uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1, bin_variances_ep1 = compute_uce(ep1_logits, labels)\n",
    "    uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2, bin_variances_ep2 = compute_uce(ep2_logits, labels)\n",
    "    uce_expert3, bin_uncertainties_expert3, bin_errors_expert3, prop_in_bin_values_expert3,bin_n_samples_ep3, bin_variances_ep3 = compute_uce(ep3_logits, labels)\n",
    "    \n",
    "    plot_dot_UCE_diagram( uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1, bin_variances_ep1,1)\n",
    "    plot_dot_UCE_diagram( uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2, bin_variances_ep2,2)\n",
    "    plot_dot_UCE_diagram( uce_expert3, bin_uncertainties_expert3, bin_errors_expert3, prop_in_bin_values_expert3,bin_n_samples_ep3, bin_variances_ep3,3)\n",
    "    \n",
    "    preds_expert1 = torch.argmax(ep1_logits, dim=1)\n",
    "    expert1_acc= accuracy(preds_expert1,labels)\n",
    "\n",
    "    preds_expert2 = torch.argmax(ep2_logits, dim=1)\n",
    "    expert2_acc= accuracy(preds_expert2,labels)\n",
    "\n",
    "    preds_expert3 = torch.argmax(ep3_logits, dim=1)\n",
    "    expert3_acc= accuracy(preds_expert3,labels)\n",
    "\n",
    "    print(phase,'expert1_acc: ',expert1_acc,'expert2_acc: ',expert2_acc,'expert3_acc: ',expert3_acc)\n",
    "    print(\"1: \",uce_expert1,\" 2: \",uce_expert2,' 3: ',uce_expert3)\n",
    "\n",
    "\n",
    "    #計算table準確度\n",
    "    table_pred_ep12 = choose_best_expert_ex(ep1_logits, ep2_logits,labels,val_uce_list_ep1,val_uce_list_ep2)\n",
    "    table_acc_ep12 = accuracy(table_pred_ep12,labels)\n",
    "\n",
    "    table_expert_ep13 = choose_best_expert_ex(ep1_logits, ep3_logits, labels,val_uce_list_ep1,val_uce_list_ep3)\n",
    "    table_acc_ep13 = accuracy(table_expert_ep13,labels)\n",
    "\n",
    "    table_pred_ep23 = choose_best_expert_ex(ep2_logits, ep3_logits,labels,val_uce_list_ep2,val_uce_list_ep3)\n",
    "    table_acc_ep23 = accuracy(table_pred_ep23,labels)\n",
    "\n",
    "    # 計算3位專家綜合準確度\n",
    "    tabel_pred_ep123 = choose_best_three_expert(ep1_logits,ep2_logits,ep3_logits,labels,val_uce_list_ep1,val_uce_list_ep2,val_uce_list_ep3)\n",
    "    tabel_acc_ep123 = accuracy(tabel_pred_ep123,labels)\n",
    "    \n",
    "    tabel_pred_ep123_new = choose_best_three_expert_new(ep1_logits,ep2_logits,ep3_logits,labels,val_uce_list_ep1,val_uce_list_ep2,val_uce_list_ep3)\n",
    "    tabel_acc_ep123_new = accuracy(tabel_pred_ep123_new,labels)\n",
    "\n",
    "\n",
    "    # 簡單投票，都不一樣選2\n",
    "    simple_voting_pred_12 = voting_(preds_expert1, preds_expert2, default_expert=1)\n",
    "    simple_voting_acc_12 = accuracy(simple_voting_pred_12, labels)\n",
    "\n",
    "    simple_voting_pred_23 = voting_(preds_expert2, preds_expert3, default_expert=1)\n",
    "    simple_voting_acc_23 = accuracy(simple_voting_pred_23, labels)\n",
    "\n",
    "    simple_voting_pred_13 = voting_(preds_expert1, preds_expert3, default_expert=1)\n",
    "    simple_voting_acc_13 = accuracy(simple_voting_pred_13, labels)\n",
    "\n",
    "    # 回到原始函數，進行三個專家的簡單投票\n",
    "    simple_voting_pred_123 = voting(preds_expert1, preds_expert2, preds_expert3, default_expert=1)\n",
    "    simple_voting_acc_123 = accuracy(simple_voting_pred_123, labels)\n",
    "\n",
    "    # 加權投票，都不一樣選2\n",
    "    weighted_voting_pred_12 = weighted_voting_(preds_expert1, preds_expert2, weights=[0.5, 0.5], default_expert=1)\n",
    "    weighted_voting_acc_12 = accuracy(weighted_voting_pred_12, labels)\n",
    "\n",
    "    weighted_voting_pred_23 = weighted_voting_(preds_expert2, preds_expert3, weights=[0.5, 0.5], default_expert=1)\n",
    "    weighted_voting_acc_23 = accuracy(weighted_voting_pred_23, labels)\n",
    "\n",
    "    weighted_voting_pred_13 = weighted_voting_(preds_expert1, preds_expert3, weights=[0.5, 0.5], default_expert=1)\n",
    "    weighted_voting_acc_13 = accuracy(weighted_voting_pred_13, labels)\n",
    "\n",
    "    # 回到原始函數，進行三個專家的加權投票\n",
    "    weighted_voting_pred_123 = weighted_voting(preds_expert1, preds_expert2, preds_expert3, weights=[0.3, 0.4, 0.3], default_expert=2)\n",
    "    weighted_voting_acc_123 = accuracy(weighted_voting_pred_123, labels)\n",
    "\n",
    "    SOE_probs_ = (ep1_logits+ep2_logits+ep3_logits)/3\n",
    "    SOE_pred = np.argmax(SOE_probs_, axis=1)\n",
    "    SOE_acc_123 =accuracy(SOE_pred,labels)\n",
    "\n",
    "    POE_probs_ = torch.stack([ep1_logits, ep2_logits,ep3_logits])\n",
    "    POE_probs = product_of_experts(POE_probs_)\n",
    "    POE_pred = np.argmax(POE_probs, axis=1)\n",
    "    POE_acc_123 =accuracy(POE_pred,labels)\n",
    "\n",
    "    def calculate_SOE_POE(ep1, ep2, ep3=None):\n",
    "        if ep3 is not None:\n",
    "            SOE_probs = (ep1 + ep2 + ep3) / 3\n",
    "            POE_probs = product_of_experts(torch.stack([ep1, ep2, ep3]))\n",
    "        else:\n",
    "            SOE_probs = (ep1 + ep2) / 2\n",
    "            POE_probs = product_of_experts(torch.stack([ep1, ep2]))\n",
    "\n",
    "        SOE_pred = torch.argmax(SOE_probs, dim=1)\n",
    "        POE_pred = torch.argmax(POE_probs, dim=1)\n",
    "\n",
    "        return SOE_pred, POE_pred\n",
    "    SOE_pred_12, POE_pred_12 = calculate_SOE_POE(ep1_logits, ep2_logits)\n",
    "    SOE_pred_23, POE_pred_23 = calculate_SOE_POE(ep2_logits, ep3_logits)\n",
    "    SOE_pred_13, POE_pred_13 = calculate_SOE_POE(ep1_logits, ep3_logits)\n",
    "\n",
    "    SOE_acc_12 = accuracy(SOE_pred_12, labels)\n",
    "    SOE_acc_23 = accuracy(SOE_pred_23, labels)\n",
    "    SOE_acc_13 = accuracy(SOE_pred_13, labels)\n",
    "\n",
    "    POE_acc_12 = accuracy(POE_pred_12, labels)\n",
    "    POE_acc_23 = accuracy(POE_pred_23, labels)\n",
    "    POE_acc_13 = accuracy(POE_pred_13, labels)\n",
    "\n",
    "    print(f\"Table Accuracy:\\n12: {table_acc_ep12:.3f} 23: {table_acc_ep23:.3f} 13: {table_acc_ep13:.3f} 123: {tabel_acc_ep123:.4f} 123_new: {tabel_acc_ep123_new:.4f}\\n\")\n",
    "\n",
    "    print(f\"Simple Voting Accuracy:\\n12: {simple_voting_acc_12:.3f} 23: {simple_voting_acc_23:.3f} 13: {simple_voting_acc_13:.3f} 123: {simple_voting_acc_123:.3f}\\n\")\n",
    "    print(f\"weighted Voting Accuracy:\\n12: {weighted_voting_acc_12:.3f} 23: {weighted_voting_acc_23:.3f} 13: {weighted_voting_acc_13:.3f} 123: {weighted_voting_acc_123:.3f}\\n\")\n",
    "    print(f\"SOE Accuracy:\\n12: {SOE_acc_12:.3f} 23: {SOE_acc_23:.3f} 13: {SOE_acc_13:.3f} 123: {SOE_acc_123:.4f}\\n\")\n",
    "    print(f\"POE Accuracy:\\n12: {POE_acc_12:.3f} 23: {POE_acc_23:.3f} 13: {POE_acc_13:.3f} 123: {POE_acc_123:.4f}\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def choose_best_three_expert(probs_expert1,probs_expert2,probs_expert3 ,targets,val_uce_list_ep1,val_uce_list_ep2,val_uce_list_ep3, n_bins=10):\n",
    "\n",
    "    \n",
    "#     uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1, bin_variances_ep1 = compute_uce(probs_expert1, targets, n_bins)\n",
    "#     uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2, bin_variances_ep2 = compute_uce(probs_expert2, targets_pairs, n_bins)\n",
    "#     uce_expert3, bin_uncertainties_expert3, bin_errors_expert3, prop_in_bin_values_expert3,bin_n_samples_ep3, bin_variances_ep3 = compute_uce(probs_expert3, targets, n_bins)\n",
    "    uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1,bin_variances_ep1 = val_uce_list_ep1[0],val_uce_list_ep1[1],val_uce_list_ep1[2],val_uce_list_ep1[3],val_uce_list_ep1[4],val_uce_list_ep1[5]\n",
    "    uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2,bin_variances_ep2 = val_uce_list_ep2[0],val_uce_list_ep2[1],val_uce_list_ep2[2],val_uce_list_ep2[3],val_uce_list_ep2[4],val_uce_list_ep2[5]\n",
    "    uce_expert3, bin_uncertainties_expert3, bin_errors_expert3, prop_in_bin_values_expert3,bin_n_samples_ep3,bin_variances_ep3 = val_uce_list_ep3[0],val_uce_list_ep3[1],val_uce_list_ep3[2],val_uce_list_ep3[3],val_uce_list_ep3[4],val_uce_list_ep3[5]\n",
    "\n",
    "\n",
    "\n",
    "    # Compute uncertainties for both experts\n",
    "    _, nattrs = probs_expert1.size()\n",
    "    nattrs = torch.tensor(nattrs)\n",
    "    uncertainties_expert1 = (1/torch.log(nattrs))*(-torch.sum(probs_expert1 * torch.log(probs_expert1 + 1e-12), dim=1))\n",
    "    uncertainties_expert2 = (1/torch.log(nattrs))*(-torch.sum(probs_expert2 * torch.log(probs_expert2 + 1e-12), dim=1))\n",
    "    uncertainties_expert3 = (1/torch.log(nattrs))*(-torch.sum(probs_expert3 * torch.log(probs_expert3 + 1e-12), dim=1))\n",
    "\n",
    "    # Find error rates for both experts\n",
    "    error_rates_expert1 = find_error_rates(uncertainties_expert1, bin_uncertainties_expert1, bin_errors_expert1)\n",
    "    error_rates_expert2 = find_error_rates(uncertainties_expert2, bin_uncertainties_expert2, bin_errors_expert2)\n",
    "    error_rates_expert3 = find_error_rates(uncertainties_expert3, bin_uncertainties_expert3, bin_errors_expert3)\n",
    "    # Choose the expert with lower error rate for each sample\n",
    "\n",
    "    # Get the predictions from both experts\n",
    "    preds_expert1 = torch.argmax(probs_expert1, dim=1)\n",
    "    preds_expert2 = torch.argmax(probs_expert2, dim=1)\n",
    "    preds_expert3 = torch.argmax(probs_expert3, dim=1)\n",
    "\n",
    "    # 將三個錯誤率堆疊成一個張量\n",
    "    error_rates = torch.stack([error_rates_expert1, error_rates_expert2, error_rates_expert3])\n",
    "\n",
    "    # 找出最小錯誤率的索引\n",
    "    _, min_error_rate_indices = torch.min(error_rates, dim=0)\n",
    "\n",
    "    # 根據最小錯誤率的索引選擇最終的預測\n",
    "    final_predictions = torch.where(min_error_rate_indices == 0, preds_expert1,\n",
    "                                    torch.where(min_error_rate_indices == 1, preds_expert2, preds_expert3))\n",
    "    \n",
    "    compute_mae_error_and_uncertainty(probs_expert1, probs_expert2, probs_expert3, targets,\n",
    "    uncertainties_expert1, uncertainties_expert2, uncertainties_expert3, error_rates_expert1, error_rates_expert2, error_rates_expert3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    global save_name\n",
    "    df = analyze_errors(error_rates, final_predictions, targets)\n",
    "    \n",
    "    # Check if the directory 'df' exists, if not, create it\n",
    "    if not os.path.exists('df'):\n",
    "        os.makedirs('df')\n",
    "    \n",
    "    # Save the dataframe to a CSV file in the 'df' directory\n",
    "    df.to_csv('df/'+save_name+'_error_analysis.csv', index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return final_predictions\n",
    "\n",
    "std_deviation_per_position = None\n",
    "error_rates = None\n",
    "POE_pred = None\n",
    "final_predictions = None\n",
    "\n",
    "def choose_best_three_expert_new(probs_expert1,probs_expert2,probs_expert3 ,targets,val_uce_list_ep1,val_uce_list_ep2,val_uce_list_ep3, n_bins=10):\n",
    "    global std_deviation_per_position\n",
    "    global error_rates\n",
    "    global threshold_\n",
    "    global POE_pred\n",
    "    global final_predictions\n",
    "    uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1,bin_variances_ep1 = val_uce_list_ep1[0],val_uce_list_ep1[1],val_uce_list_ep1[2],val_uce_list_ep1[3],val_uce_list_ep1[4],val_uce_list_ep1[5]\n",
    "    uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2,bin_variances_ep2 = val_uce_list_ep2[0],val_uce_list_ep2[1],val_uce_list_ep2[2],val_uce_list_ep2[3],val_uce_list_ep2[4],val_uce_list_ep2[5]\n",
    "    uce_expert3, bin_uncertainties_expert3, bin_errors_expert3, prop_in_bin_values_expert3,bin_n_samples_ep3,bin_variances_ep3 = val_uce_list_ep3[0],val_uce_list_ep3[1],val_uce_list_ep3[2],val_uce_list_ep3[3],val_uce_list_ep3[4],val_uce_list_ep3[5]\n",
    "\n",
    "\n",
    "\n",
    "    # Compute uncertainties for both experts\n",
    "    _, nattrs = probs_expert1.size()\n",
    "    nattrs = torch.tensor(nattrs)\n",
    "    uncertainties_expert1 = (1/torch.log(nattrs))*(-torch.sum(probs_expert1 * torch.log(probs_expert1 + 1e-12), dim=1))\n",
    "    uncertainties_expert2 = (1/torch.log(nattrs))*(-torch.sum(probs_expert2 * torch.log(probs_expert2 + 1e-12), dim=1))\n",
    "    uncertainties_expert3 = (1/torch.log(nattrs))*(-torch.sum(probs_expert3 * torch.log(probs_expert3 + 1e-12), dim=1))\n",
    "\n",
    "    # Find error rates for both experts\n",
    "    error_rates_expert1 = find_error_rates(uncertainties_expert1, bin_uncertainties_expert1, bin_errors_expert1)\n",
    "    error_rates_expert2 = find_error_rates(uncertainties_expert2, bin_uncertainties_expert2, bin_errors_expert2)\n",
    "    error_rates_expert3 = find_error_rates(uncertainties_expert3, bin_uncertainties_expert3, bin_errors_expert3)\n",
    "    # Choose the expert with lower error rate for each sample\n",
    "\n",
    "    # Get the predictions from both experts\n",
    "    preds_expert1 = torch.argmax(probs_expert1, dim=1)\n",
    "    preds_expert2 = torch.argmax(probs_expert2, dim=1)\n",
    "    preds_expert3 = torch.argmax(probs_expert3, dim=1)\n",
    "\n",
    "    # 將三個錯誤率堆疊成一個張量\n",
    "    error_rates = torch.stack([error_rates_expert1, error_rates_expert2, error_rates_expert3])\n",
    "    \n",
    "    std_deviation_per_position = torch.std(error_rates, dim=0)\n",
    "    mean_value = torch.mean(std_deviation_per_position)\n",
    "    print(\"mean: \",mean_value)\n",
    "#     print(std_deviation_per_position)\n",
    "    # 找出最小錯誤率的索引\n",
    "    _, min_error_rate_indices = torch.min(error_rates, dim=0)\n",
    "    \n",
    "    POE_probs_ = torch.stack([probs_expert1, probs_expert2,probs_expert3])\n",
    "    POE_probs = product_of_experts(POE_probs_)\n",
    "    POE_pred = np.argmax(POE_probs, axis=1)\n",
    "    \n",
    "    POE_pred = torch.tensor(POE_pred)  # Convert numpy array to torch tensor\n",
    "\n",
    "    SOE_probs_ = (probs_expert1+probs_expert2+probs_expert3)/3\n",
    "    SOE_pred = np.argmax(SOE_probs_, axis=1)\n",
    "\n",
    "    # 根據最小錯誤率的索引選擇最終的預測\n",
    "    final_predictions = torch.where(min_error_rate_indices == 0, preds_expert1,\n",
    "                                      torch.where(min_error_rate_indices == 1, preds_expert2, preds_expert3))\n",
    "\n",
    "    initial_predictions_probs = torch.where(min_error_rate_indices.unsqueeze(-1) == 0, probs_expert1,\n",
    "                                           torch.where(min_error_rate_indices.unsqueeze(-1) == 1, probs_expert2, probs_expert3))\n",
    "    \n",
    "    POE_probs_ = torch.stack([POE_probs,SOE_probs_,initial_predictions_probs])\n",
    "    POE_initial_predictions_probs = product_of_experts(POE_probs_)\n",
    "    SOE_initial_predictions_probs = (SOE_probs_+POE_probs+initial_predictions_probs)/2\n",
    "    \n",
    "    POE_final_predictions = np.argmax(POE_initial_predictions_probs, axis=1)\n",
    "    \n",
    "    SOE_final_predictions = np.argmax(SOE_initial_predictions_probs, axis=1)\n",
    "    \n",
    "    POE_acc =accuracy(POE_final_predictions,targets)\n",
    "    SOE_acc =accuracy(SOE_final_predictions,targets)\n",
    "    print(\"POE_SPE_acc: \",POE_acc,\"SOE_SPE_acc: \",SOE_acc)\n",
    "#     threshold = torch.quantile(std_deviation_per_position, threshold_)\n",
    "\n",
    "#     threshold = torch.quantile(uncertainties_, threshold_)\n",
    "#     print(\"threshold: \",threshold)\n",
    "    # 根據 std_deviation_per_position 更新預測\n",
    "#     final_predictions = torch.where(std_deviation_per_position < threshold, POE_pred, initial_predictions)\n",
    "#     final_predictions = torch.where(std_deviation_per_position < threshold, initial_predictions , POE_pred)\n",
    "\n",
    "    return SOE_final_predictions\n",
    "\n",
    "def compute_uce(probs, targets, n_bins=10):\n",
    "    _, nattrs =probs.size()\n",
    "    nattrs = torch.tensor(nattrs)\n",
    "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    uce = 0\n",
    "    bin_uncertainties = []\n",
    "    bin_errors = []\n",
    "    prop_in_bin_values = []\n",
    "    bin_n_samples = []\n",
    "    bin_variances = []\n",
    "    # Compute the uncertainty values (entropy)\n",
    "    uncertainties = (1/torch.log(nattrs))*(-torch.sum(probs * torch.log(probs + 1e-12), dim=1))\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        in_bin = (uncertainties >= bin_lower) * (uncertainties < bin_upper)\n",
    "        prop_in_bin = in_bin.float().mean()\n",
    "        prop_in_bin_values.append(prop_in_bin.item() if prop_in_bin.item() > 0 else None)\n",
    "        if prop_in_bin.item() > 0:\n",
    "            sample_indices = torch.where(in_bin)[0]\n",
    "            bin_targets = targets[sample_indices]\n",
    "            bin_probs = probs[sample_indices]\n",
    "            error_in_bin = (bin_targets != torch.argmax(bin_probs, dim=1)).float().mean()\n",
    "            avg_uncertainty_in_bin = uncertainties[in_bin].mean()\n",
    "            uce += torch.abs(avg_uncertainty_in_bin - error_in_bin) * prop_in_bin\n",
    "            bin_uncertainties.append(avg_uncertainty_in_bin.item())\n",
    "            bin_errors.append(error_in_bin.item())\n",
    "            n_samples_in_bin = sample_indices.size(0)\n",
    "            bin_n_samples.append(n_samples_in_bin)\n",
    "            bin_variances.append(torch.var((bin_targets != torch.argmax(bin_probs, dim=1)).float()).item())\n",
    "        else:\n",
    "            bin_uncertainties.append(None)\n",
    "            bin_errors.append(None)\n",
    "            bin_n_samples.append(None)\n",
    "            bin_variances.append(None)\n",
    "\n",
    "    return uce, bin_uncertainties, bin_errors, prop_in_bin_values, bin_n_samples, bin_variances\n",
    "\n",
    "\n",
    "def compute_mae_error_and_uncertainty(probs_expert1, probs_expert2, probs_expert3, targets, uncertainties_expert1, uncertainties_expert2, uncertainties_expert3, error_rates_expert1, error_rates_expert2, error_rates_expert3):\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    avg_uncertainty = (uncertainties_expert1 + uncertainties_expert2 + uncertainties_expert3) / 3\n",
    "    error_rates_expert1 = error_rates_expert1.to(device)\n",
    "    error_rates_expert2 = error_rates_expert2.to(device)\n",
    "    error_rates_expert3 = error_rates_expert3.to(device)\n",
    "    \n",
    "    # Get the predictions from each expert\n",
    "    preds_expert1 = torch.argmax(probs_expert1, dim=1)\n",
    "    preds_expert2 = torch.argmax(probs_expert2, dim=1)\n",
    "    preds_expert3 = torch.argmax(probs_expert3, dim=1)\n",
    "\n",
    "    # Calculate the real error rates\n",
    "    real_error_expert1 = (preds_expert1 != targets).float().mean()\n",
    "    real_error_expert2 = (preds_expert2 != targets).float().mean()\n",
    "    real_error_expert3 = (preds_expert3 != targets).float().mean()\n",
    "    \n",
    "    \n",
    "    # Calculate MAE for error rates\n",
    "    mae_error_expert1 = torch.abs(error_rates_expert1 - real_error_expert1).mean()\n",
    "    mae_error_expert2 = torch.abs(error_rates_expert2 - real_error_expert2).mean()\n",
    "    mae_error_expert3 = torch.abs(error_rates_expert3 - real_error_expert3).mean()\n",
    "    \n",
    "\n",
    "#     # Calculate MAE for uncertainties using average uncertainty as the reference\n",
    "#     mae_uncertainty_expert1 = torch.abs(uncertainties_expert1 - avg_uncertainty).mean()\n",
    "#     mae_uncertainty_expert2 = torch.abs(uncertainties_expert2 - avg_uncertainty).mean()\n",
    "#     mae_uncertainty_expert3 = torch.abs(uncertainties_expert3 - avg_uncertainty).mean()\n",
    "\n",
    "    # Print results\n",
    "    print(\"MAE Error Expert 1:\", mae_error_expert1.item())\n",
    "    print(\"MAE Error Expert 2:\", mae_error_expert2.item())\n",
    "    print(\"MAE Error Expert 3:\", mae_error_expert3.item())\n",
    "#     print(\"MAE Uncertainty Expert 1:\", mae_uncertainty_expert1.item())\n",
    "#     print(\"MAE Uncertainty Expert 2:\", mae_uncertainty_expert2.item())\n",
    "#     print(\"MAE Uncertainty Expert 3:\", mae_uncertainty_expert3.item())\n",
    "    \n",
    "    \n",
    "def analyze_errors(error_rates, final_predictions, targets, n_samples=500):\n",
    "    samples_idx = torch.randint(0, len(targets), (n_samples,))\n",
    "    \n",
    "    expert1_error_rates = error_rates[0][samples_idx].tolist()\n",
    "    expert2_error_rates = error_rates[1][samples_idx].tolist()\n",
    "    expert3_error_rates = error_rates[2][samples_idx].tolist()\n",
    "    \n",
    "    spe_results = final_predictions[samples_idx].tolist()\n",
    "    real_results = targets[samples_idx].tolist()\n",
    "    \n",
    "    # Checking if SPE results are correct\n",
    "    spe_is_correct = [1 if spe_results[i] == real_results[i] else 0 for i in range(n_samples)]\n",
    "    \n",
    "    data = {\n",
    "        \"專家1錯誤率\": expert1_error_rates,\n",
    "        \"專家2錯誤率\": expert2_error_rates,\n",
    "        \"專家3錯誤率\": expert3_error_rates,\n",
    "        \"SPE選擇結果\": spe_results,\n",
    "        \"真實結果\": real_results,\n",
    "        \"SPE結果是否正確\": spe_is_correct\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data, index=[f\"樣本{i+1}\" for i in range(n_samples)])\n",
    "    \n",
    "    # Analyze the variance\n",
    "    correct_predictions = df[df[\"SPE結果是否正確\"] == 1]\n",
    "    incorrect_predictions = df[df[\"SPE結果是否正確\"] == 0]\n",
    "    \n",
    "    variance_correct = (correct_predictions[[\"專家1錯誤率\", \"專家2錯誤率\", \"專家3錯誤率\"]].var(axis=1).mean())\n",
    "    variance_incorrect = (incorrect_predictions[[\"專家1錯誤率\", \"專家2錯誤率\", \"專家3錯誤率\"]].var(axis=1).mean())\n",
    "    \n",
    "    print(\"Average variance for correctly predicted samples:\", variance_correct)\n",
    "    print(\"Average variance for incorrectly predicted samples:\", variance_incorrect)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "root_path = '../train_bls/research/BalancedMetaSoftmax-Classification/logs/CIFAR10_LT/'\n",
    "k_fold = ''\n",
    "\n",
    "with open(root_path+ 'models/'+ k_fold + 'resnet32_softmax_imba100/train_feat_all.pkl', 'rb') as f:\n",
    "    data1 = pickle.load(f)\n",
    "ep1_val_logits = data1['logits']\n",
    "ep1_val_labels = data1['labels']\n",
    "\n",
    "with open(root_path + 'models/'+ k_fold + 'resnet32_softmax_imba100/valfeat_all.pkl', 'rb') as f:\n",
    "    data2 = pickle.load(f)\n",
    "ep1_test_logits = data2['logits']\n",
    "ep1_test_labels = data2['labels']\n",
    "\n",
    "\n",
    "with open(root_path+ 'models/'+ k_fold + 'resnet32_balanced_softmax_imba100/train_feat_all.pkl', 'rb') as f:\n",
    "    data3 = pickle.load(f)\n",
    "ep2_val_logits = data3['logits']\n",
    "ep2_val_labels = data3['labels']\n",
    "\n",
    "with open(root_path+'models/'+ k_fold + 'resnet32_balanced_softmax_imba100/valfeat_all.pkl', 'rb') as f:\n",
    "    data4 = pickle.load(f)\n",
    "ep2_test_logits = data4['logits']\n",
    "ep2_test_labels = data4['labels']\n",
    "\n",
    "\n",
    "with open(root_path+'clslearn/'+ k_fold + 'resnet32_decouple_balanced_softmax_imba100/train_feat_all.pkl', 'rb') as f:\n",
    "    data5 = pickle.load(f)\n",
    "ep3_val_logits = data5['logits']\n",
    "ep3_val_labels = data5['labels']\n",
    "\n",
    "\n",
    "with open(root_path+'clslearn/'+ k_fold + 'resnet32_decouple_balanced_softmax_imba100/valfeat_all.pkl', 'rb') as f:\n",
    "    data6 = pickle.load(f)\n",
    "ep3_test_logits = data6['logits']\n",
    "ep3_test_labels = data6['labels']\n",
    "\n",
    "with open(root_path+'clslearn/'+ k_fold + 'resnet32_balms_imba100/train_feat_all.pkl', 'rb') as f:\n",
    "    data7 = pickle.load(f)\n",
    "ep4_val_logits = data7['logits']\n",
    "ep4_val_labels = data7['labels']\n",
    "\n",
    "\n",
    "with open(root_path+'clslearn/'+ k_fold + 'resnet32_balms_imba100/valfeat_all.pkl', 'rb') as f:\n",
    "    data8 = pickle.load(f)\n",
    "ep4_test_logits = data8['logits']\n",
    "ep4_test_labels = data8['labels']\n",
    "\n",
    "\n",
    "\n",
    "val_uce_list_ep1 =[]\n",
    "val_uce_list_ep2 =[]\n",
    "val_uce_list_ep3 =[]\n",
    "\n",
    "ep1_val_logits_1 = torch.from_numpy(ep1_val_logits)\n",
    "ep2_val_logits_1 = torch.from_numpy(ep2_val_logits)\n",
    "ep3_val_logits_1 = torch.from_numpy(ep3_val_logits)\n",
    "ep4_val_logits_1 = torch.from_numpy(ep4_val_logits)\n",
    "\n",
    "ep1_test_logits_1 = torch.from_numpy(ep1_test_logits)\n",
    "ep2_test_logits_1 = torch.from_numpy(ep2_test_logits)\n",
    "ep3_test_logits_1 = torch.from_numpy(ep3_test_logits)\n",
    "ep4_test_logits_1 = torch.from_numpy(ep4_test_logits)\n",
    "\n",
    "val_label = torch.from_numpy(ep3_val_labels)\n",
    "test_label = torch.from_numpy(ep3_test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "root_path = '../train_bls/research/BalancedMetaSoftmax-Classification/logs/CIFAR10_LT/'\n",
    "k_fold = '1_'\n",
    "\n",
    "with open(root_path+ 'models/'+ k_fold + 'resnet32_softmax_imba100/train_feat_all.pkl', 'rb') as f:\n",
    "    data1 = pickle.load(f)\n",
    "ep1_val_logits = data1['logits']\n",
    "ep1_val_labels = data1['labels']\n",
    "\n",
    "with open(root_path + 'models/'+ k_fold + 'resnet32_softmax_imba100/valfeat_all.pkl', 'rb') as f:\n",
    "    data2 = pickle.load(f)\n",
    "ep1_test_logits = data2['logits']\n",
    "ep1_test_labels = data2['labels']\n",
    "\n",
    "\n",
    "with open(root_path+ 'models/'+ k_fold + 'resnet32_balanced_softmax_imba100/train_feat_all.pkl', 'rb') as f:\n",
    "    data3 = pickle.load(f)\n",
    "ep2_val_logits = data3['logits']\n",
    "ep2_val_labels = data3['labels']\n",
    "\n",
    "with open(root_path+'models/'+ k_fold + 'resnet32_balanced_softmax_imba100/valfeat_all.pkl', 'rb') as f:\n",
    "    data4 = pickle.load(f)\n",
    "ep2_test_logits = data4['logits']\n",
    "ep2_test_labels = data4['labels']\n",
    "\n",
    "\n",
    "with open(root_path+'clslearn/'+ k_fold + 'resnet32_decouple_balanced_softmax_imba100/train_feat_all.pkl', 'rb') as f:\n",
    "    data5 = pickle.load(f)\n",
    "ep3_val_logits = data5['logits']\n",
    "ep3_val_labels = data5['labels']\n",
    "\n",
    "\n",
    "with open(root_path+'clslearn/'+ k_fold + 'resnet32_decouple_balanced_softmax_imba100/valfeat_all.pkl', 'rb') as f:\n",
    "    data6 = pickle.load(f)\n",
    "ep3_test_logits = data6['logits']\n",
    "ep3_test_labels = data6['labels']\n",
    "\n",
    "with open(root_path+'clslearn/'+ k_fold + 'resnet32_balms_imba100/train_feat_all.pkl', 'rb') as f:\n",
    "    data7 = pickle.load(f)\n",
    "ep4_val_logits = data7['logits']\n",
    "ep4_val_labels = data7['labels']\n",
    "\n",
    "\n",
    "with open(root_path+'clslearn/'+ k_fold + 'resnet32_balms_imba100/valfeat_all.pkl', 'rb') as f:\n",
    "    data8 = pickle.load(f)\n",
    "ep4_test_logits = data8['logits']\n",
    "ep4_test_labels = data8['labels']\n",
    "\n",
    "\n",
    "\n",
    "val_uce_list_ep1 =[]\n",
    "val_uce_list_ep2 =[]\n",
    "val_uce_list_ep3 =[]\n",
    "\n",
    "ep1_val_logits_2 = torch.from_numpy(ep1_val_logits)\n",
    "ep2_val_logits_2 = torch.from_numpy(ep2_val_logits)\n",
    "ep3_val_logits_2 = torch.from_numpy(ep3_val_logits)\n",
    "ep4_val_logits_2 = torch.from_numpy(ep4_val_logits)\n",
    "\n",
    "ep1_test_logits_2 = torch.from_numpy(ep1_test_logits)\n",
    "ep2_test_logits_2 = torch.from_numpy(ep2_test_logits)\n",
    "ep3_test_logits_2 = torch.from_numpy(ep3_test_logits)\n",
    "ep4_test_logits_2 = torch.from_numpy(ep4_test_logits)\n",
    "\n",
    "val_label = torch.from_numpy(ep3_val_labels)\n",
    "test_label = torch.from_numpy(ep3_test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "root_path = '../train_bls/research/BalancedMetaSoftmax-Classification/logs/CIFAR10_LT/'\n",
    "k_fold = '3_'\n",
    "\n",
    "with open(root_path+ 'models/'+ k_fold + 'resnet32_softmax_imba100/train_feat_all.pkl', 'rb') as f:\n",
    "    data1 = pickle.load(f)\n",
    "ep1_val_logits = data1['logits']\n",
    "ep1_val_labels = data1['labels']\n",
    "\n",
    "with open(root_path + 'models/'+ k_fold + 'resnet32_softmax_imba100/valfeat_all.pkl', 'rb') as f:\n",
    "    data2 = pickle.load(f)\n",
    "ep1_test_logits = data2['logits']\n",
    "ep1_test_labels = data2['labels']\n",
    "\n",
    "\n",
    "with open(root_path+ 'models/'+ k_fold + 'resnet32_balanced_softmax_imba100/train_feat_all.pkl', 'rb') as f:\n",
    "    data3 = pickle.load(f)\n",
    "ep2_val_logits = data3['logits']\n",
    "ep2_val_labels = data3['labels']\n",
    "\n",
    "with open(root_path+'models/'+ k_fold + 'resnet32_balanced_softmax_imba100/valfeat_all.pkl', 'rb') as f:\n",
    "    data4 = pickle.load(f)\n",
    "ep2_test_logits = data4['logits']\n",
    "ep2_test_labels = data4['labels']\n",
    "\n",
    "\n",
    "with open(root_path+'clslearn/'+ k_fold + 'resnet32_decouple_balanced_softmax_imba100/train_feat_all.pkl', 'rb') as f:\n",
    "    data5 = pickle.load(f)\n",
    "ep3_val_logits = data5['logits']\n",
    "ep3_val_labels = data5['labels']\n",
    "\n",
    "\n",
    "with open(root_path+'clslearn/'+ k_fold + 'resnet32_decouple_balanced_softmax_imba100/valfeat_all.pkl', 'rb') as f:\n",
    "    data6 = pickle.load(f)\n",
    "ep3_test_logits = data6['logits']\n",
    "ep3_test_labels = data6['labels']\n",
    "\n",
    "with open(root_path+'clslearn/'+ k_fold + 'resnet32_balms_imba100/train_feat_all.pkl', 'rb') as f:\n",
    "    data7 = pickle.load(f)\n",
    "ep4_val_logits = data7['logits']\n",
    "ep4_val_labels = data7['labels']\n",
    "\n",
    "\n",
    "with open(root_path+'clslearn/'+ k_fold + 'resnet32_balms_imba100/valfeat_all.pkl', 'rb') as f:\n",
    "    data8 = pickle.load(f)\n",
    "ep4_test_logits = data8['logits']\n",
    "ep4_test_labels = data8['labels']\n",
    "\n",
    "\n",
    "\n",
    "val_uce_list_ep1 =[]\n",
    "val_uce_list_ep2 =[]\n",
    "val_uce_list_ep3 =[]\n",
    "\n",
    "ep1_val_logits_3 = torch.from_numpy(ep1_val_logits)\n",
    "ep2_val_logits_3 = torch.from_numpy(ep2_val_logits)\n",
    "ep3_val_logits_3 = torch.from_numpy(ep3_val_logits)\n",
    "ep4_val_logits_3 = torch.from_numpy(ep4_val_logits)\n",
    "\n",
    "ep1_test_logits_3 = torch.from_numpy(ep1_test_logits)\n",
    "ep2_test_logits_3 = torch.from_numpy(ep2_test_logits)\n",
    "ep3_test_logits_3 = torch.from_numpy(ep3_test_logits)\n",
    "ep4_test_logits_3 = torch.from_numpy(ep4_test_logits)\n",
    "\n",
    "val_label = torch.from_numpy(ep3_val_labels)\n",
    "test_label = torch.from_numpy(ep3_test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep1_val_logits=(ep1_val_logits_1 + ep1_val_logits_2 + ep1_val_logits_3)/3\n",
    "ep2_val_logits=(ep2_val_logits_1 + ep2_val_logits_2 + ep2_val_logits_3)/3\n",
    "ep3_val_logits=(ep3_val_logits_1 + ep3_val_logits_2 + ep3_val_logits_3)/3\n",
    "ep4_val_logits=(ep4_val_logits_1 + ep4_val_logits_2 + ep4_val_logits_3)/3\n",
    "\n",
    "ep1_test_logits = (ep1_test_logits_1+ep1_test_logits_2+ep1_test_logits_3)/3\n",
    "ep2_test_logits = (ep2_test_logits_1+ep2_test_logits_2+ep2_test_logits_3)/3\n",
    "ep3_test_logits = (ep3_test_logits_1+ep3_test_logits_2+ep3_test_logits_3)/3\n",
    "ep4_test_logits = (ep4_test_logits_1+ep1_test_logits_2+ep4_test_logits_3)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_three_expert(probs_expert1,probs_expert2,probs_expert3 ,targets,val_uce_list_ep1,val_uce_list_ep2,val_uce_list_ep3, n_bins=10):\n",
    "\n",
    "\n",
    "#     uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1, bin_variances_ep1 = compute_uce(probs_expert1, targets, n_bins)\n",
    "#     uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2, bin_variances_ep2 = compute_uce(probs_expert2, targets_pairs, n_bins)\n",
    "#     uce_expert3, bin_uncertainties_expert3, bin_errors_expert3, prop_in_bin_values_expert3,bin_n_samples_ep3, bin_variances_ep3 = compute_uce(probs_expert3, targets, n_bins)\n",
    "    uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1,bin_variances_ep1 = val_uce_list_ep1[0],val_uce_list_ep1[1],val_uce_list_ep1[2],val_uce_list_ep1[3],val_uce_list_ep1[4],val_uce_list_ep1[5]\n",
    "    uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2,bin_variances_ep2 = val_uce_list_ep2[0],val_uce_list_ep2[1],val_uce_list_ep2[2],val_uce_list_ep2[3],val_uce_list_ep2[4],val_uce_list_ep2[5]\n",
    "    uce_expert3, bin_uncertainties_expert3, bin_errors_expert3, prop_in_bin_values_expert3,bin_n_samples_ep3,bin_variances_ep3 = val_uce_list_ep3[0],val_uce_list_ep3[1],val_uce_list_ep3[2],val_uce_list_ep3[3],val_uce_list_ep3[4],val_uce_list_ep3[5]\n",
    "\n",
    "\n",
    "\n",
    "    # Compute uncertainties for both experts\n",
    "    _, nattrs = probs_expert1.size()\n",
    "    nattrs = torch.tensor(nattrs)\n",
    "    uncertainties_expert1 = (1/torch.log(nattrs))*(-torch.sum(probs_expert1 * torch.log(probs_expert1 + 1e-12), dim=1))\n",
    "    uncertainties_expert2 = (1/torch.log(nattrs))*(-torch.sum(probs_expert2 * torch.log(probs_expert2 + 1e-12), dim=1))\n",
    "    uncertainties_expert3 = (1/torch.log(nattrs))*(-torch.sum(probs_expert3 * torch.log(probs_expert3 + 1e-12), dim=1))\n",
    "\n",
    "    # Find error rates for both experts\n",
    "    error_rates_expert1 = find_error_rates(uncertainties_expert1, bin_uncertainties_expert1, bin_errors_expert1)\n",
    "    error_rates_expert2 = find_error_rates(uncertainties_expert2, bin_uncertainties_expert2, bin_errors_expert2)\n",
    "    error_rates_expert3 = find_error_rates(uncertainties_expert3, bin_uncertainties_expert3, bin_errors_expert3)\n",
    "    # Choose the expert with lower error rate for each sample\n",
    "\n",
    "    # Get the predictions from both experts\n",
    "    preds_expert1 = torch.argmax(probs_expert1, dim=1)\n",
    "    preds_expert2 = torch.argmax(probs_expert2, dim=1)\n",
    "    preds_expert3 = torch.argmax(probs_expert3, dim=1)\n",
    "\n",
    "    # 將三個錯誤率堆疊成一個張量\n",
    "    error_rates = torch.stack([error_rates_expert1, error_rates_expert2, error_rates_expert3])\n",
    "\n",
    "    # 找出最小錯誤率的索引\n",
    "    _, min_error_rate_indices = torch.min(error_rates, dim=0)\n",
    "\n",
    "    # 根據最小錯誤率的索引選擇最終的預測\n",
    "    final_predictions = torch.where(min_error_rate_indices == 0, preds_expert1,\n",
    "                                    torch.where(min_error_rate_indices == 1, preds_expert2, preds_expert3))\n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_three_expert_new(probs_expert1,probs_expert2,probs_expert3 ,targets,val_uce_list_ep1,val_uce_list_ep2,val_uce_list_ep3, n_bins=10):\n",
    "    global std_deviation_per_position\n",
    "    global error_rates\n",
    "    global threshold_\n",
    "    global POE_pred\n",
    "    global final_predictions\n",
    "    uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1,bin_variances_ep1 = val_uce_list_ep1[0],val_uce_list_ep1[1],val_uce_list_ep1[2],val_uce_list_ep1[3],val_uce_list_ep1[4],val_uce_list_ep1[5]\n",
    "    uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2,bin_variances_ep2 = val_uce_list_ep2[0],val_uce_list_ep2[1],val_uce_list_ep2[2],val_uce_list_ep2[3],val_uce_list_ep2[4],val_uce_list_ep2[5]\n",
    "    uce_expert3, bin_uncertainties_expert3, bin_errors_expert3, prop_in_bin_values_expert3,bin_n_samples_ep3,bin_variances_ep3 = val_uce_list_ep3[0],val_uce_list_ep3[1],val_uce_list_ep3[2],val_uce_list_ep3[3],val_uce_list_ep3[4],val_uce_list_ep3[5]\n",
    "\n",
    "\n",
    "\n",
    "    # Compute uncertainties for both experts\n",
    "    _, nattrs = probs_expert1.size()\n",
    "    nattrs = torch.tensor(nattrs)\n",
    "    uncertainties_expert1 = (1/torch.log(nattrs))*(-torch.sum(probs_expert1 * torch.log(probs_expert1 + 1e-12), dim=1))\n",
    "    uncertainties_expert2 = (1/torch.log(nattrs))*(-torch.sum(probs_expert2 * torch.log(probs_expert2 + 1e-12), dim=1))\n",
    "    uncertainties_expert3 = (1/torch.log(nattrs))*(-torch.sum(probs_expert3 * torch.log(probs_expert3 + 1e-12), dim=1))\n",
    "\n",
    "    # Find error rates for both experts\n",
    "    error_rates_expert1 = find_error_rates(uncertainties_expert1, bin_uncertainties_expert1, bin_errors_expert1)\n",
    "    error_rates_expert2 = find_error_rates(uncertainties_expert2, bin_uncertainties_expert2, bin_errors_expert2)\n",
    "    error_rates_expert3 = find_error_rates(uncertainties_expert3, bin_uncertainties_expert3, bin_errors_expert3)\n",
    "    # Choose the expert with lower error rate for each sample\n",
    "\n",
    "    # Get the predictions from both experts\n",
    "    preds_expert1 = torch.argmax(probs_expert1, dim=1)\n",
    "    preds_expert2 = torch.argmax(probs_expert2, dim=1)\n",
    "    preds_expert3 = torch.argmax(probs_expert3, dim=1)\n",
    "\n",
    "    # 將三個錯誤率堆疊成一個張量\n",
    "    error_rates = torch.stack([error_rates_expert1, error_rates_expert2, error_rates_expert3])\n",
    "    \n",
    "    std_deviation_per_position = torch.std(error_rates, dim=0)\n",
    "    mean_value = torch.mean(std_deviation_per_position)\n",
    "    print(\"mean: \",mean_value)\n",
    "#     print(std_deviation_per_position)\n",
    "    # 找出最小錯誤率的索引\n",
    "    _, min_error_rate_indices = torch.min(error_rates, dim=0)\n",
    "    \n",
    "    POE_probs_ = torch.stack([probs_expert1, probs_expert2,probs_expert3])\n",
    "    POE_probs = product_of_experts(POE_probs_)\n",
    "    POE_pred = np.argmax(POE_probs, axis=1)\n",
    "    \n",
    "    POE_pred = torch.tensor(POE_pred)  # Convert numpy array to torch tensor\n",
    "\n",
    "    SOE_probs_ = (probs_expert1+probs_expert2+probs_expert3)/3\n",
    "    SOE_pred = np.argmax(SOE_probs_, axis=1)\n",
    "\n",
    "    # 根據最小錯誤率的索引選擇最終的預測\n",
    "    final_predictions = torch.where(min_error_rate_indices == 0, preds_expert1,\n",
    "                                      torch.where(min_error_rate_indices == 1, preds_expert2, preds_expert3))\n",
    "\n",
    "    initial_predictions_probs = torch.where(min_error_rate_indices.unsqueeze(-1) == 0, probs_expert1,\n",
    "                                           torch.where(min_error_rate_indices.unsqueeze(-1) == 1, probs_expert2, probs_expert3))\n",
    "    \n",
    "    POE_probs_ = torch.stack([POE_probs,SOE_probs_,initial_predictions_probs])\n",
    "    POE_initial_predictions_probs = product_of_experts(POE_probs_)\n",
    "    SOE_initial_predictions_probs = (SOE_probs_+POE_probs+initial_predictions_probs)/2\n",
    "    \n",
    "    POE_final_predictions = np.argmax(POE_initial_predictions_probs, axis=1)\n",
    "    \n",
    "    SOE_final_predictions = np.argmax(SOE_initial_predictions_probs, axis=1)\n",
    "    \n",
    "    POE_acc =accuracy(POE_final_predictions,targets)\n",
    "    SOE_acc =accuracy(SOE_final_predictions,targets)\n",
    "#     print(\"POE_SPE_acc: \",POE_acc,\"SOE_SPE_acc: \",SOE_acc)\n",
    "#     threshold = torch.quantile(std_deviation_per_position, threshold_)\n",
    "\n",
    "#     threshold = torch.quantile(uncertainties_, threshold_)\n",
    "#     print(\"threshold: \",threshold)\n",
    "    # 根據 std_deviation_per_position 更新預測\n",
    "#     final_predictions = torch.where(std_deviation_per_position < threshold, POE_pred, initial_predictions)\n",
    "#     final_predictions = torch.where(std_deviation_per_position < threshold, initial_predictions , POE_pred)\n",
    "\n",
    "    return SOE_final_predictions\n",
    "\n",
    "def compute_uce(probs, targets, n_bins=10):\n",
    "    _, nattrs =probs.size()\n",
    "    nattrs = torch.tensor(nattrs)\n",
    "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    uce = 0\n",
    "    bin_uncertainties = []\n",
    "    bin_errors = []\n",
    "    prop_in_bin_values = []\n",
    "    bin_n_samples = []\n",
    "    bin_variances = []\n",
    "    # Compute the uncertainty values (entropy)\n",
    "    uncertainties = (1/torch.log(nattrs))*(-torch.sum(probs * torch.log(probs + 1e-12), dim=1))\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        in_bin = (uncertainties >= bin_lower) * (uncertainties < bin_upper)\n",
    "        prop_in_bin = in_bin.float().mean()\n",
    "        prop_in_bin_values.append(prop_in_bin.item() if prop_in_bin.item() > 0 else None)\n",
    "        if prop_in_bin.item() > 0:\n",
    "            sample_indices = torch.where(in_bin)[0]\n",
    "            bin_targets = targets[sample_indices]\n",
    "            bin_probs = probs[sample_indices]\n",
    "            error_in_bin = (bin_targets != torch.argmax(bin_probs, dim=1)).float().mean()\n",
    "            avg_uncertainty_in_bin = uncertainties[in_bin].mean()\n",
    "            uce += torch.abs(avg_uncertainty_in_bin - error_in_bin) * prop_in_bin\n",
    "            bin_uncertainties.append(avg_uncertainty_in_bin.item())\n",
    "            bin_errors.append(error_in_bin.item())\n",
    "            n_samples_in_bin = sample_indices.size(0)\n",
    "            bin_n_samples.append(n_samples_in_bin)\n",
    "            bin_variances.append(torch.var((bin_targets != torch.argmax(bin_probs, dim=1)).float()).item())\n",
    "        else:\n",
    "            bin_uncertainties.append(None)\n",
    "            bin_errors.append(None)\n",
    "            bin_n_samples.append(None)\n",
    "            bin_variances.append(None)\n",
    "\n",
    "    return uce, bin_uncertainties, bin_errors, prop_in_bin_values, bin_n_samples, bin_variances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_per_position = None\n",
    "error_rates = None\n",
    "POE_pred = None\n",
    "final_predictions = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test1-------------------\n",
      "test expert1_acc:  0.7978 expert2_acc:  0.8413 expert3_acc:  0.8418\n",
      "1:  tensor(0.1027)  2:  tensor(0.0113)  3:  tensor(0.0149)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/notebooks/anaconda3/envs/clip/lib/python3.7/site-packages/ipykernel_launcher.py:176: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPE_UCE:  tensor(0.0656) SOE_UCE:  tensor(0.0104) POE_UCE:  tensor(0.1636)\n",
      "mean:  tensor(0.0356)\n",
      "POE_SPE_acc:  0.8329 SOE_SPE_acc:  0.8324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/notebooks/anaconda3/envs/clip/lib/python3.7/site-packages/ipykernel_launcher.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Accuracy:\n",
      "12: 0.829 23: 0.844 13: 0.831 123: 0.8325 123_new: 0.8324\n",
      "\n",
      "Simple Voting Accuracy:\n",
      "12: 0.798 23: 0.841 13: 0.798 123: 0.798\n",
      "\n",
      "weighted Voting Accuracy:\n",
      "12: 0.798 23: 0.841 13: 0.798 123: 0.841\n",
      "\n",
      "SOE Accuracy:\n",
      "12: 0.825 23: 0.841 13: 0.827 123: 0.8385\n",
      "\n",
      "POE Accuracy:\n",
      "12: 0.826 23: 0.841 13: 0.830 123: 0.8360\n",
      "\n",
      "------------test2-------------------\n",
      "test expert1_acc:  0.7903 expert2_acc:  0.8433 expert3_acc:  0.841\n",
      "1:  tensor(0.1110)  2:  tensor(0.0133)  3:  tensor(0.0130)\n",
      "SPE_UCE:  tensor(0.0674) SOE_UCE:  tensor(0.0408) POE_UCE:  tensor(0.1426)\n",
      "mean:  tensor(0.0520)\n",
      "POE_SPE_acc:  0.8579 SOE_SPE_acc:  0.8551\n",
      "Table Accuracy:\n",
      "12: 0.852 23: 0.844 13: 0.854 123: 0.8539 123_new: 0.8551\n",
      "\n",
      "Simple Voting Accuracy:\n",
      "12: 0.790 23: 0.843 13: 0.790 123: 0.790\n",
      "\n",
      "weighted Voting Accuracy:\n",
      "12: 0.790 23: 0.843 13: 0.790 123: 0.843\n",
      "\n",
      "SOE Accuracy:\n",
      "12: 0.846 23: 0.843 13: 0.845 123: 0.8571\n",
      "\n",
      "POE Accuracy:\n",
      "12: 0.846 23: 0.842 13: 0.848 123: 0.8570\n",
      "\n",
      "------------test3-------------------\n",
      "test expert1_acc:  0.7966 expert2_acc:  0.8427 expert3_acc:  0.8425\n",
      "1:  tensor(0.1115)  2:  tensor(0.0132)  3:  tensor(0.0150)\n",
      "SPE_UCE:  tensor(0.0669) SOE_UCE:  tensor(0.0448) POE_UCE:  tensor(0.1370)\n",
      "mean:  tensor(0.0544)\n",
      "POE_SPE_acc:  0.8618 SOE_SPE_acc:  0.8554\n",
      "Table Accuracy:\n",
      "12: 0.854 23: 0.842 13: 0.853 123: 0.8550 123_new: 0.8554\n",
      "\n",
      "Simple Voting Accuracy:\n",
      "12: 0.797 23: 0.843 13: 0.797 123: 0.797\n",
      "\n",
      "weighted Voting Accuracy:\n",
      "12: 0.797 23: 0.843 13: 0.797 123: 0.843\n",
      "\n",
      "SOE Accuracy:\n",
      "12: 0.851 23: 0.843 13: 0.851 123: 0.8602\n",
      "\n",
      "POE Accuracy:\n",
      "12: 0.853 23: 0.843 13: 0.856 123: 0.8626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold_ = 0\n",
    "\n",
    "save_name = 'bls_134_1'\n",
    "\n",
    "val_uce_list_ep1 , val_uce_list_ep2 ,val_uce_list_ep3 = [],[],[]\n",
    "\n",
    "cal_val_state(ep1_val_logits_1, ep3_val_logits_1, ep4_val_logits_1,val_label,phase='val')\n",
    "print('------------test1-------------------')\n",
    "cal_val_state(ep1_test_logits_1,ep3_test_logits_1,ep4_test_logits_1,test_label,phase='test')\n",
    "\n",
    "val_uce_list_ep1 , val_uce_list_ep2 ,val_uce_list_ep3 = [],[],[]\n",
    "cal_val_state(ep1_val_logits_2, ep3_val_logits_2, ep4_val_logits_2, val_label,phase='val')\n",
    "print('------------test2-------------------')\n",
    "cal_val_state(ep1_test_logits_2,ep3_test_logits_2,ep4_test_logits_2,test_label,phase='test')\n",
    "\n",
    "val_uce_list_ep1 , val_uce_list_ep2 ,val_uce_list_ep3 = [],[],[]\n",
    "cal_val_state(ep1_val_logits_3, ep3_val_logits_3, ep4_val_logits_3, val_label,phase='val')\n",
    "print('------------test3-------------------')\n",
    "cal_val_state(ep1_test_logits_3,ep3_test_logits_3,ep4_test_logits_3,test_label,phase='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test1-------------------\n",
      "test expert1_acc:  0.7978 expert2_acc:  0.8413 expert3_acc:  0.8418\n",
      "1:  tensor(0.1027)  2:  tensor(0.0113)  3:  tensor(0.0149)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/notebooks/anaconda3/envs/clip/lib/python3.7/site-packages/ipykernel_launcher.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POE_SPE_acc:  0.8329 SOE_SPE_acc:  0.8324\n",
      "Table Accuracy:\n",
      "12: 0.829 23: 0.844 13: 0.831 123: 0.8325 123_new: 0.8518\n",
      "\n",
      "Simple Voting Accuracy:\n",
      "12: 0.798 23: 0.841 13: 0.798 123: 0.798\n",
      "\n",
      "weighted Voting Accuracy:\n",
      "12: 0.798 23: 0.841 13: 0.798 123: 0.841\n",
      "\n",
      "SOE Accuracy:\n",
      "12: 0.825 23: 0.841 13: 0.827 123: 0.8385\n",
      "\n",
      "POE Accuracy:\n",
      "12: 0.826 23: 0.841 13: 0.830 123: 0.8360\n",
      "\n",
      "------------test2-------------------\n",
      "test expert1_acc:  0.7903 expert2_acc:  0.8433 expert3_acc:  0.841\n",
      "1:  tensor(0.1110)  2:  tensor(0.0133)  3:  tensor(0.0130)\n",
      "POE_SPE_acc:  0.8579 SOE_SPE_acc:  0.8551\n",
      "Table Accuracy:\n",
      "12: 0.852 23: 0.844 13: 0.854 123: 0.8539 123_new: 0.8518\n",
      "\n",
      "Simple Voting Accuracy:\n",
      "12: 0.790 23: 0.843 13: 0.790 123: 0.790\n",
      "\n",
      "weighted Voting Accuracy:\n",
      "12: 0.790 23: 0.843 13: 0.790 123: 0.843\n",
      "\n",
      "SOE Accuracy:\n",
      "12: 0.846 23: 0.843 13: 0.845 123: 0.8571\n",
      "\n",
      "POE Accuracy:\n",
      "12: 0.846 23: 0.842 13: 0.848 123: 0.8570\n",
      "\n",
      "------------test3-------------------\n",
      "test expert1_acc:  0.7945 expert2_acc:  0.8444 expert3_acc:  0.8397\n",
      "1:  tensor(0.1112)  2:  tensor(0.0099)  3:  tensor(0.0160)\n",
      "POE_SPE_acc:  0.8582 SOE_SPE_acc:  0.8523\n"
     ]
    }
   ],
   "source": [
    "threshold_ = 0\n",
    "\n",
    "save_name = 'bls_134_1'\n",
    "\n",
    "val_uce_list_ep1 , val_uce_list_ep2 ,val_uce_list_ep3 = [],[],[]\n",
    "\n",
    "cal_val_state(ep1_val_logits_1, ep3_val_logits_1, ep4_val_logits_1,val_label,phase='val')\n",
    "print('------------test1-------------------')\n",
    "cal_val_state(ep1_test_logits_1,ep3_test_logits_1,ep4_test_logits_1,test_label,phase='test')\n",
    "\n",
    "val_uce_list_ep1 , val_uce_list_ep2 ,val_uce_list_ep3 = [],[],[]\n",
    "cal_val_state(ep1_val_logits_2, ep3_val_logits_2, ep4_val_logits_2, val_label,phase='val')\n",
    "print('------------test2-------------------')\n",
    "cal_val_state(ep1_test_logits_2,ep3_test_logits_2,ep4_test_logits_2,test_label,phase='test')\n",
    "\n",
    "val_uce_list_ep1 , val_uce_list_ep2 ,val_uce_list_ep3 = [],[],[]\n",
    "cal_val_state(ep1_val_logits_3, ep3_val_logits_3, ep4_val_logits_3, val_label,phase='val')\n",
    "print('------------test3-------------------')\n",
    "cal_val_state(ep1_test_logits_3,ep3_test_logits_3,ep4_test_logits_3,test_label,phase='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "1t9aQ4nVSuLP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test-------------------\n",
      "test expert1_acc:  0.8352 expert2_acc:  0.8759 expert3_acc:  0.8592\n",
      "1:  tensor(0.0683)  2:  tensor(0.0358)  3:  tensor(0.0168)\n",
      "Table Accuracy:\n",
      "12: 0.868 23: 0.878 13: 0.855 123: 0.872\n",
      "\n",
      "Simple Voting Accuracy:\n",
      "12: 0.835 23: 0.876 13: 0.835 123: 0.835\n",
      "\n",
      "weighted Voting Accuracy:\n",
      "12: 0.835 23: 0.876 13: 0.835 123: 0.876\n",
      "\n",
      "SOE Accuracy:\n",
      "12: 0.868 23: 0.882 13: 0.852 123: 0.871\n",
      "\n",
      "POE Accuracy:\n",
      "12: 0.868 23: 0.883 13: 0.853 123: 0.871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save_name = 'bls_124_best'\n",
    "cal_val_state(ep1_val_logits,ep2_val_logits,ep4_val_logits,val_label,phase='val')\n",
    "print('------------test-------------------')\n",
    "cal_val_state(ep1_test_logits,ep2_test_logits,ep4_test_logits,test_label,phase='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "KvneyZ93alcs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test-------------------\n",
      "test expert1_acc:  0.8629 expert2_acc:  0.8432 expert3_acc:  0.859\n",
      "1:  tensor(0.0468)  2:  tensor(0.0117)  3:  tensor(0.0177)\n",
      "Table Accuracy:\n",
      "12: 0.873 23: 0.860 13: 0.874 123: 0.875\n",
      "\n",
      "Simple Voting Accuracy:\n",
      "12: 0.863 23: 0.843 13: 0.863 123: 0.863\n",
      "\n",
      "weighted Voting Accuracy:\n",
      "12: 0.863 23: 0.843 13: 0.863 123: 0.843\n",
      "\n",
      "SOE Accuracy:\n",
      "12: 0.878 23: 0.859 13: 0.876 123: 0.875\n",
      "\n",
      "POE Accuracy:\n",
      "12: 0.879 23: 0.860 13: 0.877 123: 0.879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save_name = 'bls_234'\n",
    "cal_val_state(ep2_val_logits,ep3_val_logits,ep4_val_logits,val_label,phase='val')\n",
    "print('------------test-------------------')\n",
    "cal_val_state(ep2_test_logits,ep3_test_logits,ep4_test_logits,test_label,phase='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "EYWVWKP_cmV3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test-------------------\n",
      "test expert1_acc:  0.8165 expert2_acc:  0.8432 expert3_acc:  0.859\n",
      "1:  tensor(0.0860)  2:  tensor(0.0117)  3:  tensor(0.0177)\n",
      "Table Accuracy:\n",
      "12: 0.855 23: 0.860 13: 0.852 123: 0.857\n",
      "\n",
      "Simple Voting Accuracy:\n",
      "12: 0.817 23: 0.843 13: 0.817 123: 0.817\n",
      "\n",
      "weighted Voting Accuracy:\n",
      "12: 0.817 23: 0.843 13: 0.817 123: 0.843\n",
      "\n",
      "SOE Accuracy:\n",
      "12: 0.856 23: 0.859 13: 0.845 123: 0.861\n",
      "\n",
      "POE Accuracy:\n",
      "12: 0.857 23: 0.860 13: 0.846 123: 0.859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save_name = 'bls_134'\n",
    "cal_val_state(ep1_val_logits,ep3_val_logits,ep4_val_logits,val_label,phase='val')\n",
    "print('------------test-------------------')\n",
    "cal_val_state(ep1_test_logits,ep3_test_logits,ep4_test_logits,test_label,phase='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Ja489nfcode"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "clip",
   "language": "python",
   "name": "clip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
